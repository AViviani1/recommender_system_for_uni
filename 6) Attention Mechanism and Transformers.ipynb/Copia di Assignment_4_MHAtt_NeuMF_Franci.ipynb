{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1Fiufp1FCSfFPN4sbQkSRPoP7N_le9YU3","timestamp":1684097409107}]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","metadata":{"id":"yVlwEEkWlXEu"},"source":["# LAB 4: Attention"]},{"cell_type":"markdown","source":["Assignment made by:\n","\n","Alessandro Viviani 843234\n","\n","Francesca Arredondo 820354\n","\n","Fabio Turchetta 898572\n"],"metadata":{"id":"RS7fI7wlbnTU"}},{"cell_type":"code","execution_count":6,"metadata":{"id":"Yji9-7jslKRz","executionInfo":{"status":"ok","timestamp":1684144417291,"user_tz":-120,"elapsed":257,"user":{"displayName":"Francesca Arredondo","userId":"12580341919802368774"}}},"outputs":[],"source":["import os\n","import time\n","import random\n","import argparse\n","import numpy as np \n","import pandas as pd \n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import torch.utils.data as data\n","from torch.utils.data import Dataset, DataLoader\n","import matplotlib.pyplot as plt \n","import torch.nn.functional as F\n","from torch.nn import TransformerEncoder, TransformerEncoderLayer"]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"arJu3Re7XCky","outputId":"ff861fdd-b5a2-45f9-bbb2-e76283fd37a3","executionInfo":{"status":"ok","timestamp":1684144417541,"user_tz":-120,"elapsed":8,"user":{"displayName":"Francesca Arredondo","userId":"12580341919802368774"}}},"outputs":[{"output_type":"execute_result","data":{"text/plain":["<torch._C.Generator at 0x7f7511a79730>"]},"metadata":{},"execution_count":7}],"source":["np.random.seed(55)\n","torch.manual_seed(5)"]},{"cell_type":"code","execution_count":8,"metadata":{"id":"IkcVzJcY5TS_","executionInfo":{"status":"ok","timestamp":1684144417541,"user_tz":-120,"elapsed":6,"user":{"displayName":"Francesca Arredondo","userId":"12580341919802368774"}}},"outputs":[],"source":["use_cuda = torch.cuda.is_available()\n","device = torch.device(\"cpu\")"]},{"cell_type":"code","execution_count":9,"metadata":{"id":"qcffYFMdxDcI","executionInfo":{"status":"ok","timestamp":1684144417542,"user_tz":-120,"elapsed":6,"user":{"displayName":"Francesca Arredondo","userId":"12580341919802368774"}}},"outputs":[],"source":["dataset_origin = {'100k': 'u.data', '1M': 'ratings.dat'}\n","\n","num_sample_data = '100k'\n","DATA_PATH = 'drive/MyDrive/Colab Notebooks/ml-100k/u.data'.format(dataset_origin[num_sample_data]) "]},{"cell_type":"code","execution_count":10,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XX0MtVLM4E_k","outputId":"853d7dc1-1e4a-4278-9732-c134034b83c4","executionInfo":{"status":"ok","timestamp":1684144437141,"user_tz":-120,"elapsed":19605,"user":{"displayName":"Francesca Arredondo","userId":"12580341919802368774"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"markdown","source":["Class Rating_Dataset"],"metadata":{"id":"NdGJWM8FsgmQ"}},{"cell_type":"code","execution_count":11,"metadata":{"id":"hmlijxEoYXDj","cellView":"form","executionInfo":{"status":"ok","timestamp":1684144437142,"user_tz":-120,"elapsed":9,"user":{"displayName":"Francesca Arredondo","userId":"12580341919802368774"}}},"outputs":[],"source":["#@title\n","class Rating_Datset(Dataset):\n","\tdef __init__(self, user_list, item_list, rating_list):\n","\t\tsuper(Rating_Datset, self).__init__()\n","\t\tself.user_list = user_list\n","\t\tself.item_list = item_list\n","\t\tself.rating_list = rating_list\n","\n","\tdef __len__(self):\n","\t\treturn len(self.user_list)\n","\n","\tdef __getitem__(self, idx):\n","\t\tuser = self.user_list[idx]\n","\t\titem = self.item_list[idx]\n","\t\trating = self.rating_list[idx]\n","\t\t\n","\t\treturn (\n","\t\t\ttorch.tensor(user, dtype=torch.long),\n","\t\t\ttorch.tensor(item, dtype=torch.long),\n","\t\t\ttorch.tensor(rating, dtype=torch.float)\n","\t\t\t)"]},{"cell_type":"markdown","source":["Class NCF_Data"],"metadata":{"id":"ihc99EIhsnll"}},{"cell_type":"code","execution_count":12,"metadata":{"id":"FxZCDy4tYkRZ","cellView":"form","executionInfo":{"status":"ok","timestamp":1684144437142,"user_tz":-120,"elapsed":7,"user":{"displayName":"Francesca Arredondo","userId":"12580341919802368774"}}},"outputs":[],"source":["#@title\n","class NCF_Data(object):\n","\t\"\"\"\n","\tConstruct Dataset for NCF\n","\t\"\"\"\n","\tdef __init__(self, args, ratings):\n","\t\tself.ratings = ratings\n","\t\tself.num_ng = args.num_ng\n","\t\tself.num_ng_test = args.num_ng_test\n","\t\tself.batch_size = args.batch_size\n","\n","\t\tself.preprocess_ratings = self._reindex(self.ratings)\n","\n","\t\tself.user_pool = set(self.ratings['user_id'].unique())\n","\t\tself.item_pool = set(self.ratings['item_id'].unique())\n","\n","\t\tself.train_ratings, self.test_ratings = self._leave_one_out(self.preprocess_ratings)\n","\t\tself.negatives = self._negative_sampling(self.preprocess_ratings)\n","\n","\t\n","\tdef _reindex(self, ratings):\n","\t\t\"\"\"\n","\t\tProcess dataset to reindex userID and itemID, also set rating as binary feedback\n","\t\t\"\"\"\n","\t\tuser_list = list(ratings['user_id'].drop_duplicates())\n","\t\tuser2id = {w: i for i, w in enumerate(user_list)}\n","\n","\t\titem_list = list(ratings['item_id'].drop_duplicates())\n","\t\titem2id = {w: i for i, w in enumerate(item_list)}\n","\n","\t\tratings['user_id'] = ratings['user_id'].apply(lambda x: user2id[x])\n","\t\tratings['item_id'] = ratings['item_id'].apply(lambda x: item2id[x])\n","\t\tratings['rating'] = ratings['rating'].apply(lambda x: float(x > 0))\n","\t\treturn ratings\n","\n","\tdef _leave_one_out(self, ratings):\n","\t\t\"\"\"\n","\t\tleave-one-out evaluation protocol in paper https://www.comp.nus.edu.sg/~xiangnan/papers/ncf.pdf\n","\t\t\"\"\"\n","\t\tratings['rank_latest'] = ratings.groupby(['user_id'])['timestamp'].rank(method='first', ascending=False)\n","\t\ttest = ratings.loc[ratings['rank_latest'] == 1]\n","\t\ttrain = ratings.loc[ratings['rank_latest'] > 1]\n","\t\tassert train['user_id'].nunique()==test['user_id'].nunique(), 'Not Match Train User with Test User'\n","\t\treturn train[['user_id', 'item_id', 'rating']], test[['user_id', 'item_id', 'rating']]\n","\n","\tdef _negative_sampling(self, ratings):\n","\t\tinteract_status = (\n","\t\t\tratings.groupby('user_id')['item_id']\n","\t\t\t.apply(set)\n","\t\t\t.reset_index()\n","\t\t\t.rename(columns={'item_id': 'interacted_items'}))\n","\t\tinteract_status['negative_items'] = interact_status['interacted_items'].apply(lambda x: self.item_pool - x)\n","\t\tinteract_status['negative_samples'] = interact_status['negative_items'].apply(lambda x: random.sample(x, self.num_ng_test))\n","\t\treturn interact_status[['user_id', 'negative_items', 'negative_samples']]\n","\n","\tdef get_train_instance(self):\n","\t\tusers, items, ratings = [], [], []\n","\t\ttrain_ratings = pd.merge(self.train_ratings, self.negatives[['user_id', 'negative_items']], on='user_id')\n","\t\ttrain_ratings['negatives'] = train_ratings['negative_items'].apply(lambda x: random.sample(x, self.num_ng))\n","\t\tfor row in train_ratings.itertuples():\n","\t\t\tusers.append(int(row.user_id))\n","\t\t\titems.append(int(row.item_id))\n","\t\t\tratings.append(float(row.rating))\n","\t\t\tfor i in range(self.num_ng):\n","\t\t\t\tusers.append(int(row.user_id))\n","\t\t\t\titems.append(int(row.negatives[i]))\n","\t\t\t\tratings.append(float(0))  # negative samples get 0 rating\n","\t\tdataset = Rating_Datset(\n","\t\t\tuser_list=users,\n","\t\t\titem_list=items,\n","\t\t\trating_list=ratings)\n","\t\treturn DataLoader(dataset, batch_size=self.batch_size, shuffle=True, num_workers=4)\n","\n","\tdef get_test_instance(self):\n","\t\tusers, items, ratings = [], [], []\n","\t\ttest_ratings = pd.merge(self.test_ratings, self.negatives[['user_id', 'negative_samples']], on='user_id')\n","\t\tfor row in test_ratings.itertuples():\n","\t\t\tusers.append(int(row.user_id))\n","\t\t\titems.append(int(row.item_id))\n","\t\t\tratings.append(float(row.rating))\n","\t\t\tfor i in getattr(row, 'negative_samples'):\n","\t\t\t\tusers.append(int(row.user_id))\n","\t\t\t\titems.append(int(i))\n","\t\t\t\tratings.append(float(0))\n","\t\tdataset = Rating_Datset(\n","\t\t\tuser_list=users,\n","\t\t\titem_list=items,\n","\t\t\trating_list=ratings)\n","\t\treturn DataLoader(dataset, batch_size=self.num_ng_test+1, shuffle=False, num_workers=2)"]},{"cell_type":"markdown","source":["Metrics"],"metadata":{"id":"7w1aoplWs0rK"}},{"cell_type":"code","execution_count":13,"metadata":{"id":"uTaIX7H52i-a","cellView":"form","executionInfo":{"status":"ok","timestamp":1684144437142,"user_tz":-120,"elapsed":7,"user":{"displayName":"Francesca Arredondo","userId":"12580341919802368774"}}},"outputs":[],"source":["#@title\n","def hit(ng_item, pred_items):\n","\tif ng_item in pred_items:\n","\t\treturn 1\n","\treturn 0\n","\n","\n","def ndcg(ng_item, pred_items):\n","\tif ng_item in pred_items:\n","\t\tindex = pred_items.index(ng_item)\n","\t\treturn np.reciprocal(np.log2(index+2))\n","\treturn 0\n","\n","\n","def metrics(model, test_loader, top_k, device):\n","\tHR, NDCG = [], []\n","\n","\tfor user, item, label in test_loader:\n","\t\tuser = user.to(device)\n","\t\titem = item.to(device)\n","\n","\t\tpredictions = model(user, item)\n","\t\t_, indices = torch.topk(predictions, top_k)\n","\t\trecommends = torch.take(\n","\t\t\t\titem, indices).cpu().numpy().tolist()\n","\n","\t\tng_item = item[0].item() # leave one-out evaluation has only one item per user\n","\t\tHR.append(hit(ng_item, recommends))\n","\t\tNDCG.append(ndcg(ng_item, recommends))\n","\n","\treturn np.mean(HR), np.mean(NDCG)"]},{"cell_type":"markdown","source":["Class NeuMF"],"metadata":{"id":"8cF9aqO_tQKK"}},{"cell_type":"code","source":["import torch.nn.functional as F\n","from torch.nn import TransformerEncoder, TransformerEncoderLayer\n","\n","class NeuMF(nn.Module):\n","    def __init__(self, args, num_users, num_items):\n","        super(NeuMF, self).__init__()\n","        self.num_users = num_users\n","        self.num_items = num_items\n","        self.factor_num = args.factor_num\n","        self.layers = args.layers\n","        self.hidden_dim = args.hidden_dim\n","\n","        self.gmf_user_embedding = nn.Embedding(self.num_users, self.factor_num)\n","        self.gmf_item_embedding = nn.Embedding(self.num_items, self.factor_num)\n","        self.mlp_user_embedding = nn.Embedding(self.num_users, self.factor_num)\n","        self.mlp_item_embedding = nn.Embedding(self.num_items, self.factor_num)\n","\n","        mlp_layer_sizes = self.layers\n","        self.mlp_layers = nn.ModuleList()\n","        for idx, (in_size, out_size) in enumerate(zip(mlp_layer_sizes[:-1], mlp_layer_sizes[1:])):\n","            self.mlp_layers.append(nn.Linear(in_size, out_size))\n","\n","        self.transformer_layer = TransformerEncoderLayer(d_model=self.hidden_dim, nhead=8)\n","        self.transformer_encoder = TransformerEncoder(self.transformer_layer, num_layers=1)\n","\n","        self.output_layer = nn.Linear(in_features=mlp_layer_sizes[-1] + self.hidden_dim + self.factor_num , out_features=1)\n","        self.logistic = torch.sigmoid\n","\n","    def forward(self, user_indices, item_indices):\n","        # Matrix factorization branch\n","        gmf_user_embedding = self.gmf_user_embedding(user_indices)\n","        gmf_item_embedding = self.gmf_item_embedding(item_indices)\n","        gmf_output = torch.mul(gmf_user_embedding, gmf_item_embedding) # GMF layer\n","\n","        # Multilayer perceptron branch\n","        mlp_user_embedding = self.mlp_user_embedding(user_indices)\n","        mlp_item_embedding = self.mlp_item_embedding(item_indices)\n","        mlp_output = torch.cat([mlp_user_embedding, mlp_item_embedding], dim=1)\n","        for idx, _ in enumerate(range(len(self.mlp_layers))):\n","            mlp_output = self.mlp_layers[idx](mlp_output)\n","            mlp_output = nn.ReLU()(mlp_output)\n","\n","        # Transformer Branch\n","        transformer_input = torch.cat([gmf_user_embedding, gmf_item_embedding], dim=1) #64\n","        transformer_input = transformer_input.unsqueeze(0)\n","        transformer_output = self.transformer_encoder(transformer_input) #?\n","        transformer_output = transformer_output.squeeze()\n","\n","        # Concatenate GMF, MLP and Transformer Outputs and pass through final layer\n","        concatenated = torch.cat([gmf_output, mlp_output, transformer_output], dim=1) #64+8+?\n","        logits = self.output_layer(concatenated)\n","        rating = self.logistic(logits)\n","        return rating.squeeze()"],"metadata":{"id":"Ri5_pOvnttkq","executionInfo":{"status":"ok","timestamp":1684144437142,"user_tz":-120,"elapsed":7,"user":{"displayName":"Francesca Arredondo","userId":"12580341919802368774"}}},"execution_count":14,"outputs":[]},{"cell_type":"code","execution_count":15,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TzFNcyild5y8","outputId":"5d35a1d6-3378-4715-df14-697f2bf96952","executionInfo":{"status":"ok","timestamp":1684144437143,"user_tz":-120,"elapsed":8,"user":{"displayName":"Francesca Arredondo","userId":"12580341919802368774"}}},"outputs":[{"output_type":"execute_result","data":{"text/plain":["_StoreAction(option_strings=['--hidden_dim'], dest='hidden_dim', nargs=None, const=None, default=64, type=<class 'int'>, choices=None, required=False, help=None, metavar=None)"]},"metadata":{},"execution_count":15}],"source":["#collapse-hide\n","parser = argparse.ArgumentParser()\n","parser.add_argument(\"--seed\", \n","\ttype=int, \n","\tdefault=51, \n","\thelp=\"Seed\")\n","parser.add_argument(\"--lr\", \n","\ttype=float, \n","\tdefault=0.001, \n","\thelp=\"learning rate\")\n","parser.add_argument(\"--dropout\", \n","\ttype=float,\n","\tdefault=0.2,  \n","\thelp=\"dropout rate\")\n","parser.add_argument(\"--batch_size\", \n","\ttype=int, \n","\tdefault=256, \n","\thelp=\"batch size for training\")\n","parser.add_argument(\"--epochs\", \n","\ttype=int,\n","\tdefault=10,  \n","\thelp=\"training epoches\")\n","parser.add_argument(\"--top_k\", \n","\ttype=int, \n","\tdefault=10, \n","\thelp=\"compute metrics@top_k\")\n","parser.add_argument(\"--factor_num\", \n","\ttype=int,\n","\tdefault=32, \n","\thelp=\"predictive factors numbers in the model\")\n","parser.add_argument(\"--layers\",\n","    nargs='+', \n","    default=[64,32,16,8],\n","    help=\"MLP layers. Note that the first layer is the concatenation of user \\\n","    and item embeddings. So layers[0]/2 is the embedding size.\")\n","parser.add_argument(\"--num_ng\", \n","\ttype=int,\n","\tdefault=4, \n","\thelp=\"Number of negative samples for training set\")\n","parser.add_argument(\"--num_ng_test\", \n","\ttype=int,\n","\tdefault=100, \n","\thelp=\"Number of negative samples for test set\")\n","parser.add_argument(\"--out\", \n","\tdefault=True,\n","\thelp=\"save model or not\")\n","parser.add_argument(\"--hidden_dim\", \n","\ttype=int, \n","\tdefault=64, \n","\t)"]},{"cell_type":"markdown","source":["# Main"],"metadata":{"id":"seLI6-BS_-wY"}},{"cell_type":"code","execution_count":16,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"coXQgQWYd51r","outputId":"5abb1958-d68a-440a-cd75-555015c595f1","executionInfo":{"status":"ok","timestamp":1684144439669,"user_tz":-120,"elapsed":2531,"user":{"displayName":"Francesca Arredondo","userId":"12580341919802368774"}}},"outputs":[{"output_type":"stream","name":"stderr","text":["<ipython-input-12-fa01be874ac8>:53: DeprecationWarning: Sampling from a set deprecated\n","since Python 3.9 and will be removed in a subsequent version.\n","  interact_status['negative_samples'] = interact_status['negative_items'].apply(lambda x: random.sample(x, self.num_ng_test))\n","<ipython-input-12-fa01be874ac8>:59: DeprecationWarning: Sampling from a set deprecated\n","since Python 3.9 and will be removed in a subsequent version.\n","  train_ratings['negatives'] = train_ratings['negative_items'].apply(lambda x: random.sample(x, self.num_ng))\n","/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:561: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(_create_warning_msg(\n"]}],"source":[" # set device and parameters\n","args = parser.parse_args(\"\")\n","device = torch.device(\"cpu\")\n","\n","# load data\n","ml_100k = pd.read_csv(\n","\tDATA_PATH, \n","\tsep=\"\\t\", \n","\tnames = ['user_id', 'item_id', 'rating', 'timestamp'], \n","\tengine='python')\n","\n","# set the num_users, items\n","num_users = ml_100k['user_id'].nunique()+1\n","num_items = ml_100k['item_id'].nunique()+1\n","\n","# construct the train and test datasets\n","data = NCF_Data(args, ml_100k)\n","train_loader = data.get_train_instance()\n","test_loader = data.get_test_instance()"]},{"cell_type":"code","source":["# set model and loss, optimizer\n","model = NeuMF(args, num_users, num_items)\n","model = model.to(device)\n","loss_function = nn.BCELoss()\n","optimizer = optim.Adam(model.parameters(), lr=args.lr)"],"metadata":{"id":"5H8ua7Y-xZy0","executionInfo":{"status":"ok","timestamp":1684144439669,"user_tz":-120,"elapsed":6,"user":{"displayName":"Francesca Arredondo","userId":"12580341919802368774"}}},"execution_count":17,"outputs":[]},{"cell_type":"markdown","source":[],"metadata":{"id":"u18L_rCP6QGY"}},{"cell_type":"code","source":["# train, evaluation\n","best_hr = 0\n","for epoch in range(1, args.epochs+1):\n","\tmodel.train() # Enable dropout (if have).\n","\tstart_time = time.time()\n","\n","\tfor user, item, label in train_loader:\n","\t\tuser = user.to(device)\n","\t\titem = item.to(device)\n","\t\tlabel = label.to(device)\n","\n","\t\toptimizer.zero_grad()\n","\t\tprediction = model(user, item)\n","\t\tloss = loss_function(prediction, label)\n","\t\tloss.backward()\n","\t\toptimizer.step()\n","\t\t#writer.add_scalar('loss/Train_loss', loss.item(), epoch)\n","\n","\tmodel.eval()\n","\tHR, NDCG = metrics(model, test_loader, args.top_k, device)\n","\t#writer.add_scalar('Perfomance/HR@10', HR, epoch)\n","\t#writer.add_scalar('Perfomance/NDCG@10', NDCG, epoch)\n","\n","\telapsed_time = time.time() - start_time\n","\tprint(\"Epoch {:03d}\".format(epoch) + \" time to train: \" + \n","\t\t\ttime.strftime(\"%H: %M: %S\", time.gmtime(elapsed_time)))\n","\tprint(\"HR: {:.3f}\\tNDCG: {:.3f}\".format(np.mean(HR), np.mean(NDCG)))\n","\n","\tif HR > best_hr:\n","\t\tbest_hr, best_ndcg, best_epoch = HR, NDCG, epoch"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Hz1CtehkuCWM","outputId":"39dc63b1-6459-425b-c904-a29e7a2a6126"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:561: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(_create_warning_msg(\n"]}]}]}